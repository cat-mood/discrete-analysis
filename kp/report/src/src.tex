\section{Описание}
Требуется написать реализацию наивного байесовского классификатора.

Наивный байесовский классификатор (Naive Bayes classifier) —- вероятностный классификатор на основе формулы Байеса 
со строгим (наивным) предположением о независимости признаков между собой при заданном классе, 
что сильно упрощает задачу классификации из-за оценки одномерных вероятностных плотностей вместо одной многомерной\cite{Habr}.

Формула Байеса: $$P(A | B) = \frac{P(B | A) P(A)}{P(B)}$$

В контексте машинного обучения формула Байеса приобретает следующий вид: $$P(y_k | X) = \frac{P(y_k) P(X | y_k)}{P(X)}$$

В конечном счёте правило классификации будет пропорционально выбору класса с максимальной апостериорной вероятностью:
$$y_k \propto \arg \max_{y_k} P(y_k) \prod^n_{i = 1} P(X_i | y_k)$$

Чтобы получить вероятность $P(X_i | y_k)$ на практике, я вычисляю частоту слова $X_i$ в классе $y_k$.
Вероятность $P(y_k)$ -- это отношение количества слов в классе $y_k$ к количеству всех слов, использовавшихся для
обучения модели.

Для того, чтобы вероятность не оказалась равной нулю, я использую сглаживание. При вычислении $P(X_i | y_k) = \frac{X_i}{X}$
я добавляю в числитель единицу.

Для задачи с подбором множества классов я отбираю их по порогу $$\beta = 0.5 + \frac{1}{\max y_i},$$ где
$\max y_i$ -- это максимальное число слов в классе. Число $0.5$ было выбрано эмпирически.

Отбор я осуществляю по отношению вероятности класса к максимальной вероятности:
$$\frac{P(X_i | y_k)}{\max P(X_i | y_k)} > \beta.$$ Если это условие выполняется, то класс включается в предсказание.

\pagebreak

\section{Исходный код}
\begin{longtable}{|p{7.5cm}|p{7.5cm}|}
\hline
\rowcolor{lightgray}
\multicolumn{2}{|c|} {word\_tools.h}\\
\hline
void ToLowerCase(std::string\& str)&Преобразование строки в нижний регистр.\\
\hline
std::vector<std::string> Split(const std::string\& s, const std::string\& delimiters)&Разделить строку на слова.\\
\hline
std::vector<uint64\_t> UIntSplit(const std::string\& s, const std::string\& delimeters)&Разделить строку на целые числа.\\
\hline
\rowcolor{lightgray}
\multicolumn{2}{|c|} {classifier.h}\\
\hline
void Fit(const std::vector<std::pair<TWord, TCategoryName>>\& data)&Обучение модели.\\
\hline
TCategoryName Predict(std::string\& str)&Предсказать классы предложений.\\
\hline
void SaveToFile(const std::string\& filename) const&Сохранить веса в файл.\\
\hline
void LoadFromFile(const std::string\& filename)&Загрузить веса из файла.\\
\hline
static double Accuracy(const TConfusionMatrix\& matrix)&Метрика accuracy.\\
\hline
static double Precision(const TConfusionMatrix\& matrix, TCategoryName category)&Метрика точности.\\
\hline
static double Recall(const TConfusionMatrix\& matrix, TCategoryName category)&Метрика полноты.\\
\hline
static double F1(const TConfusionMatrix\& matrix, TCategoryName category)&F1 метрика.\\
\hline
\end{longtable}

\begin{lstlisting}[language=C++]
using TWord = std::string;
using TCategoryName = uint64_t;
using TConfusionMatrix = std::vector<std::vector<uint64_t>>;

class TNaiveBayesClassifier {
private:
	using TCategory = std::unordered_map<TWord, uint64_t>;

	std::unordered_map<TCategoryName, TCategory> categoriesWeights;
	double beta = 0.5;
public:
	TNaiveBayesClassifier() {}
	void Fit(const std::vector<std::pair<TWord, std::vector<TCategoryName>>>& data);
	std::vector<TCategoryName> Predict(std::string& str);
	void SaveToFile(const std::string& filename) const;
	void LoadFromFile(const std::string& filename);

	std::unordered_map<TCategoryName, TCategory> GetCategoriesWeights() const {
		return categoriesWeights;
	}

	uint64_t GetCategoriesNumber() const {
		return categoriesWeights.size();
	}

	static double Accuracy(const TConfusionMatrix& matrix);

	static double Precision(const TConfusionMatrix& matrix, TCategoryName category);

	static double Recall(const TConfusionMatrix& matrix, TCategoryName category);

	static double F1(const TConfusionMatrix& matrix, TCategoryName category);
};
\end{lstlisting}
\pagebreak

\section{Консоль}
\begin{alltt}
	cat-mood@nuclear-box:~/programming/mai-da-labs/kp/build$ ./kp_exe learn --input learn.txt --output out.txt
	cat-mood@nuclear-box:~/programming/mai-da-labs/kp/build$ ./kp_exe classify --input test.txt \
	 --output ans1.txt --stats out.txt
\end{alltt}
\pagebreak
